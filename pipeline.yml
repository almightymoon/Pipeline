# ===========================================================
# Enterprise ML/AI CI/CD Pipeline with GPU Support & Model Parallelism
# Supports: Python, Java, ML Projects with Multi-GPU Training
# ===========================================================
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: enterprise-ml-pipeline
  labels:
    app.kubernetes.io/name: ml-pipeline
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/component: ci-cd
spec:
  description: "Enterprise-grade CI/CD pipeline for multi-language AI/ML projects with GPU acceleration"
  workspaces:
    - name: shared-data
      description: "Shared workspace for code, datasets, and artifacts"
    - name: docker-credentials
      description: "Docker registry credentials"
    - name: vault-secrets
      description: "Vault secrets for secure operations"
  params:
    - name: git-url
      type: string
      description: "Git repository URL"
    - name: git-revision
      type: string
      default: "main"
      description: "Git revision to checkout"
    - name: image-registry
      type: string
      default: "harbor.example.com/ml-team"
      description: "Container image registry"
    - name: image-tag
      type: string
      default: "latest"
      description: "Container image tag"
    - name: project-type
      type: string
      default: "python"
      description: "Project type: python, java, ml, or multi"
    - name: gpu-count
      type: string
      default: "1"
      description: "Number of GPUs for training"
    - name: enable-model-parallelism
      type: string
      default: "false"
      description: "Enable DeepSpeed/Megatron model parallelism"
    - name: dataset-version
      type: string
      default: "latest"
      description: "Dataset version to use"
    - name: jira-project
      type: string
      default: "ML"
      description: "Jira project key for reporting"
  tasks:
    # ===========================================================
    # Stage 1: Code Commit & Validation
    # ===========================================================
    - name: git-clone
      taskRef:
        name: git-clone
        kind: ClusterTask
      params:
        - name: url
          value: "$(params.git-url)"
        - name: revision
          value: "$(params.git-revision)"
        - name: submodules
          value: "true"
      workspaces:
        - name: output
          workspace: shared-data

    - name: validate-commit
      runAfter: [git-clone]
      taskRef:
        name: validate-commit
        kind: Task
      params:
        - name: PROJECT_TYPE
          value: "$(params.project-type)"
        - name: JIRA_PROJECT
          value: "$(params.jira-project)"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 2: Multi-Language Build & Containerization
    # ===========================================================
    - name: build-python
      runAfter: [validate-commit]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["python", "ml", "multi"]
      taskRef:
        name: buildah
        kind: ClusterTask
      params:
        - name: IMAGE
          value: "$(params.image-registry)/python-app:$(params.image-tag)"
        - name: DOCKERFILE
          value: "Dockerfile.python"
        - name: CONTEXT
          value: "."
      workspaces:
        - name: source
          workspace: shared-data
        - name: dockerconfig
          workspace: docker-credentials

    - name: build-java
      runAfter: [validate-commit]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["java", "multi"]
      taskRef:
        name: buildah
        kind: ClusterTask
      params:
        - name: IMAGE
          value: "$(params.image-registry)/java-app:$(params.image-tag)"
        - name: DOCKERFILE
          value: "Dockerfile.java"
        - name: CONTEXT
          value: "."
      workspaces:
        - name: source
          workspace: shared-data
        - name: dockerconfig
          workspace: docker-credentials

    - name: build-ml
      runAfter: [validate-commit]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["ml", "multi"]
      taskRef:
        name: buildah
        kind: ClusterTask
      params:
        - name: IMAGE
          value: "$(params.image-registry)/ml-app:$(params.image-tag)"
        - name: DOCKERFILE
          value: "Dockerfile.ml"
        - name: CONTEXT
          value: "."
      workspaces:
        - name: source
          workspace: shared-data
        - name: dockerconfig
          workspace: docker-credentials

    # ===========================================================
    # Stage 3: Security Analysis & Code Quality
    # ===========================================================
    - name: sast-scan
      runAfter: [build-python, build-java, build-ml]
      taskRef:
        name: sonarqube-scanner
        kind: Task
      params:
        - name: SONAR_HOST_URL
          value: "https://sonarqube.example.com"
        - name: SONAR_PROJECT_KEY
          value: "$(params.jira-project)-$(params.project-type)"
      workspaces:
        - name: source
          workspace: shared-data
        - name: sonar-token
          workspace: vault-secrets

    - name: dependency-scan
      runAfter: [sast-scan]
      taskRef:
        name: dependency-track-scan
        kind: Task
      params:
        - name: PROJECT_TYPE
          value: "$(params.project-type)"
        - name: DEPENDENCY_TRACK_URL
          value: "https://dependency-track.example.com"
      workspaces:
        - name: source
          workspace: shared-data

    - name: security-scan
      runAfter: [dependency-scan]
      taskRef:
        name: defectdojo-scan
        kind: Task
      params:
        - name: DEFECTDOJO_URL
          value: "https://defectdojo.example.com"
        - name: SCAN_TYPE
          value: "SAST"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 4: Automated Testing (Multi-Language)
    # ===========================================================
    - name: unit-tests-python
      runAfter: [security-scan]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["python", "ml", "multi"]
      taskRef:
        name: run-python-tests
        kind: Task
      params:
        - name: TEST_CMD
          value: "pytest tests/ -v --cov=src --cov-report=xml"
        - name: PYTHON_VERSION
          value: "3.9"
      workspaces:
        - name: source
          workspace: shared-data

    - name: unit-tests-java
      runAfter: [security-scan]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["java", "multi"]
      taskRef:
        name: run-java-tests
        kind: Task
      params:
        - name: MAVEN_GOALS
          value: "test"
        - name: JAVA_VERSION
          value: "17"
      workspaces:
        - name: source
          workspace: shared-data

    - name: integration-tests
      runAfter: [unit-tests-python, unit-tests-java]
      taskRef:
        name: run-integration-tests
        kind: Task
      params:
        - name: TEST_ENV
          value: "staging"
        - name: PROJECT_TYPE
          value: "$(params.project-type)"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 5: Continuous Dataset Preparation
    # ===========================================================
    - name: dataset-validation
      runAfter: [integration-tests]
      taskRef:
        name: dataset-validator
        kind: Task
      params:
        - name: DATASET_VERSION
          value: "$(params.dataset-version)"
        - name: OUTPUT_FORMAT
          value: "json"
        - name: VALIDATION_SCHEMA
          value: "schemas/dataset-schema.json"
      workspaces:
        - name: source
          workspace: shared-data

    - name: dataset-transform
      runAfter: [dataset-validation]
      taskRef:
        name: dataset-transformer
        kind: Task
      params:
        - name: INPUT_PATH
          value: "/datasets/raw"
        - name: OUTPUT_PATH
          value: "/datasets/processed"
        - name: TRANSFORM_CONFIG
          value: "configs/dataset-transform.yaml"
      workspaces:
        - name: source
          workspace: shared-data

    - name: dataset-versioning
      runAfter: [dataset-transform]
      taskRef:
        name: dataset-versioner
        kind: Task
      params:
        - name: DATASET_NAME
          value: "$(params.jira-project)-dataset"
        - name: VERSION_TAG
          value: "$(params.dataset-version)"
        - name: NEXUS_URL
          value: "https://nexus.example.com"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 6: GPU-Accelerated Testing & Validation
    # ===========================================================
    - name: gpu-smoke-test
      runAfter: [dataset-versioning]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["ml", "multi"]
      taskRef:
        name: gpu-validation
        kind: Task
      params:
        - name: GPU_COUNT
          value: "$(params.gpu-count)"
        - name: VALIDATION_SCRIPT
          value: "scripts/validate_gpu.py"
        - name: CUDA_VERSION
          value: "11.8"
      resources:
        limits:
          nvidia.com/gpu: "$(params.gpu-count)"
      workspaces:
        - name: source
          workspace: shared-data

    - name: model-validation
      runAfter: [gpu-smoke-test]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["ml", "multi"]
      taskRef:
        name: model-validator
        kind: Task
      params:
        - name: MODEL_PATH
          value: "/models/checkpoint"
        - name: VALIDATION_METRICS
          value: "accuracy,precision,recall,f1"
        - name: THRESHOLD
          value: "0.85"
      resources:
        limits:
          nvidia.com/gpu: "1"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 7: Distributed Model Training (Optional)
    # ===========================================================
    - name: distributed-training
      runAfter: [model-validation]
      when:
        - input: "$(params.enable-model-parallelism)"
          operator: in
          values: ["true"]
      taskRef:
        name: deepspeed-trainer
        kind: Task
      params:
        - name: GPU_COUNT
          value: "$(params.gpu-count)"
        - name: DEEPSPEED_CONFIG
          value: "configs/deepspeed.json"
        - name: MODEL_CONFIG
          value: "configs/model-config.yaml"
        - name: ENABLE_MEGATRON
          value: "true"
      resources:
        limits:
          nvidia.com/gpu: "$(params.gpu-count)"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 8: Artifact Publishing & Registry
    # ===========================================================
    - name: publish-images
      runAfter: [distributed-training]
      taskRef:
        name: publish-to-harbor
        kind: Task
      params:
        - name: REGISTRY_URL
          value: "$(params.image-registry)"
        - name: IMAGE_TAG
          value: "$(params.image-tag)"
        - name: SIGN_IMAGES
          value: "true"
      workspaces:
        - name: source
          workspace: shared-data
        - name: dockerconfig
          workspace: docker-credentials

    - name: publish-models
      runAfter: [publish-images]
      when:
        - input: "$(params.project-type)"
          operator: in
          values: ["ml", "multi"]
      taskRef:
        name: publish-models
        kind: Task
      params:
        - name: MODEL_REGISTRY
          value: "harbor.example.com/ml-models"
        - name: MODEL_VERSION
          value: "$(params.image-tag)"
        - name: FORMAT
          value: "onnx,pytorch"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 9: Deployment & Testing
    # ===========================================================
    - name: deploy-staging
      runAfter: [publish-models]
      taskRef:
        name: deploy-to-staging
        kind: Task
      params:
        - name: ENVIRONMENT
          value: "staging"
        - name: NAMESPACE
          value: "ml-staging"
        - name: HELM_CHART
          value: "charts/ml-app"
      workspaces:
        - name: source
          workspace: shared-data

    - name: e2e-tests
      runAfter: [deploy-staging]
      taskRef:
        name: run-e2e-tests
        kind: Task
      params:
        - name: TEST_SUITE
          value: "e2e"
        - name: ENVIRONMENT
          value: "staging"
        - name: PROJECT_TYPE
          value: "$(params.project-type)"
      workspaces:
        - name: source
          workspace: shared-data

    # ===========================================================
    # Stage 10: Monitoring & Reporting
    # ===========================================================
    - name: push-metrics
      runAfter: [e2e-tests]
      taskRef:
        name: push-to-prometheus
        kind: Task
      params:
        - name: PROMETHEUS_URL
          value: "https://prometheus.example.com"
        - name: METRICS_FILE
          value: "metrics/pipeline-metrics.json"
        - name: JOB_NAME
          value: "ml-pipeline-$(params.project-type)"
      workspaces:
        - name: source
          workspace: shared-data

    - name: update-jira
      runAfter: [push-metrics]
      taskRef:
        name: jira-reporter
        kind: Task
      params:
        - name: JIRA_URL
          value: "https://jira.example.com"
        - name: PROJECT_KEY
          value: "$(params.jira-project)"
        - name: REPORT_TYPE
          value: "pipeline-results"
        - name: INCLUDE_METRICS
          value: "true"
      workspaces:
        - name: source
          workspace: shared-data
        - name: jira-credentials
          workspace: vault-secrets

    # ===========================================================
    # Stage 11: Production Deployment (Conditional)
    # ===========================================================
    - name: deploy-production
      runAfter: [update-jira]
      when:
        - input: "$(params.image-tag)"
          operator: notin
          values: ["latest", "dev"]
      taskRef:
        name: deploy-to-production
        kind: Task
      params:
        - name: ENVIRONMENT
          value: "production"
        - name: NAMESPACE
          value: "ml-production"
        - name: HELM_CHART
          value: "charts/ml-app"
        - name: ENABLE_BLUE_GREEN
          value: "true"
      workspaces:
        - name: source
          workspace: shared-data
---
# ===========================================================
# ArgoCD GitOps Application
# ===========================================================
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ml-prod
spec:
  project: default
  source:
    repoURL: 'git@github.com:yourorg/infra.git'
    path: 'charts/ml-app'
    targetRevision: main
  destination:
    server: 'https://kubernetes.default.svc'
    namespace: ml-prod
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
---
# ===========================================================
# Distributed DeepSpeed Training Job
# ===========================================================
apiVersion: batch/v1
kind: Job
metadata:
  name: deepspeed-train
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: trainer
          image: harbor.example.com/ml-team/deepspeed:latest
          command: ["deepspeed", "--num_gpus=4", "train.py", "--config", "ds_config.json"]
          resources:
            limits:
              nvidia.com/gpu: 4
      nodeSelector:
        accelerator: nvidia
---
# ===========================================================
# Harbor Registry Secret
# ===========================================================
apiVersion: v1
kind: Secret
metadata:
  name: harbor-creds
  namespace: ml-prod
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: <BASE64_ENCODED_JSON>
---
# ===========================================================
# Vault CSI Secret Provider
# ===========================================================
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: vault-provider
  namespace: ml-prod
spec:
  provider: vault
  parameters:
    vaultAddress: "https://vault.example.com"
    roleName: "ml-app"
    objects: |
      - objectName: "db-credentials"
        secretPath: "secret/data/ml/db"
        secretKey: "password"
---
# ===========================================================
# Prometheus Alert Rules for GPU Utilization
# ===========================================================
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: gpu-alerts
  namespace: monitoring
spec:
  groups:
    - name: gpu.rules
      rules:
        - alert: GPUHighUtilization
          expr: dcgm_gpu_utilization > 90
          for: 10m
          labels:
            severity: critical
          annotations:
            summary: "GPU utilization > 90% for 10m"
---
# ===========================================================
# OPA Policy: Require Resource Limits & Signed Images
# ===========================================================
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredResources
metadata:
  name: require-limits
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Pod"]
  parameters:
    limits: ["cpu", "memory", "nvidia.com/gpu"]
---
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sAllowedRepos
metadata:
  name: signed-images-only
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Pod"]
  parameters:
    repos:
      - "harbor.example.com/ml-team"
